<<<<<<< HEAD
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Week 3: CNN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVHN can be downloaded from http://ufldl.stanford.edu/housenumbers/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "\n",
    "train = loadmat('../week_2/test_32x32.mat')\n",
    "test = loadmat('../week_2/test_32x32.mat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`train` and `test` are dictionaries with keys `'X'` and `'y'`. The values are numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 3, 26032)\n",
      "(26032, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train['X'].shape)\n",
    "print(train['y'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 3, 26032)\n",
      "(26032, 1)\n"
     ]
    }
   ],
   "source": [
    "print(test['X'].shape)\n",
    "print(test['y'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "training_set = np.transpose(train['X'], (3, 0, 1, 2)).astype(np.float32)\n",
    "training_labels = train['y']\n",
    "\n",
    "test_set = np.transpose(test['X'], (3, 0, 1, 2)).astype(np.float32)\n",
    "test_labels = test['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = training_set.shape[0]\n",
    "n_test = test_set.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digit: 4\n"
     ]
    }
   ],
   "source": [
    "example = np.random.choice(np.arange(n_train))\n",
    "\n",
    "image = training_set[example]\n",
    "label = training_labels[example][0]\n",
    "\n",
    "if label == 10:\n",
    "    label = 0\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "\n",
    "print(\"Digit: {}\".format(label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the images to grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_grayscale(images):\n",
    "    images = np.add.reduce(images, keepdims=True, axis=3)\n",
    "    images = images / 3.0\n",
    "    return images / 128.0 - 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_gs = convert_to_grayscale(training_set)\n",
    "test_set_gs = convert_to_grayscale(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26032, 32, 32, 1)\n",
      "(26032, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "print(training_set_gs.shape)\n",
    "print(test_set_gs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAFflJREFUeJztnV2MnGd1x3/H6/VH7PX3R9aOsTGNVCJUAlpFVCBEQaAUIQWkKoILyEWEUUWkItGLKJVKKvUCqgLioqIyTUSoaELKh4iqiJJGSBFcBDZpcAxpS4gCie14HeNvr7O29/RiXlfrMOfs7LMz73j7/H+S5dn3zDPvmWf2v+/M859zHnN3hBD1sWzYCQghhoPEL0SlSPxCVIrEL0SlSPxCVIrEL0SlSPxCVIrEL0SlSPxCVMryxQw2s1uBrwAjwD+5++ez+2/cuNF37NjRNVbyTUMzK4otWxb/zSsZl43Jntfs7GxRrGSusudcGsued0T2vC5evFh0rmw+oljp61JKNo/95PDhw5w8ebKnF6ZY/GY2AvwD8H7gZeBnZvaIu/8yGrNjxw4efPDBrrGSX/ZsQlesWBHGVq9eHcZWrly54HHLl8fTeOnSpTB24cKFMHb+/PkwViKS7Hldd911YSybq2yOozzOnTsXjpmamlrw40Eu5Ndee63r8ZmZmQWPgfz3tPT3cWRkZMHnip7zJz7xiXDM61nMn6NbgOfd/QV3nwEeAm5bxOMJIVpkMeLfCbw05+eXm2NCiCXAwD+ImNk+M5s0s8kTJ04M+nRCiB5ZjPgPAbvm/HxDc+wq3H2/u0+4+8TGjRsXcTohRD9ZjPh/BtxoZm80sxXAR4FH+pOWEGLQFK/2u/slM7sL+Hc6Vt/97v6LbMzMzAy//e1vS0/5e2QrqNkK9tjYWBhbs2ZNGLt8+XLX49lKerZyfObMmTCWrYpnTkCUY7YSvXbt2jC2bt26MFbiBGSr7BltNp0ptYmjVXvIV+6zcYNkUT6/uz8KPNqnXIQQLaJv+AlRKRK/EJUi8QtRKRK/EJUi8QtRKYta7V8o58+f5+mnn17wuNHR0a7HV61aFY7ZtGlTGNu8eXPRuMgijPKD3JY7depUGDt+/HhRLLIIM6sss/q2bt1aFIss08yezQqkSgt7IvpdNbkU0ZVfiEqR+IWoFIlfiEqR+IWoFIlfiEppdbX/7Nmz/OQnP+kay1Zzo1X9DRs2hGOuv/76MDY+Ph7GsmKbqCQ5K+w5e/ZsGDt27FgYO3z4cBh75ZVXwljkBGQtw7ICnWwe9+7dG8YiJyB7vO3bt4ex7PcjW7mPCp1Ke/hFjzcfmcsxLHTlF6JSJH4hKkXiF6JSJH4hKkXiF6JSJH4hKqVVq296epqDBw92jWVWTmRFZUU4mcWW2TVZbHp6uuvxzMbJrMPMsst6Hb700kthLLIPswKj9evXh7HMIswKgqIeioPYCqtNsn57JduXDRNd+YWoFIlfiEqR+IWoFIlfiEqR+IWoFIlfiEpZlNVnZi8CZ4DLwCV3n8juf/HixbBaLbNJoqq5zL7K+sFlFlXWFzCqBMtyP3nyZBg7evRoGDty5EgYO3To9/ZD/T+mpqa6Hs+2Dcti2XZdFy9eDGOR/ZlVQLZZaVfawy+z+rKtvK7FvoD98Pn/xN1f7cPjCCFaRG/7haiUxYrfgR+a2VNmtq8fCQkh2mGxb/vf5e6HzGwb8JiZ/Ze7PzH3Ds0fBf1hEOIaY1FXfnc/1Pw/BXwPuKXLffa7+8R8i4FCiHYpFr+ZrTGzsSu3gQ8A3at2hBDXHIt5278d+F5jcy0H/sXdf5ANMLPQgrt06VI4LoqVjIHyJoyRPZTZOJmNllX8ZVWJUXUhxFV4MzMz4ZhsPjJrq8ROzZqFZpRWA5a8ZqV5ZJZvNo8RmXVY+js8l2Lxu/sLwFsXnYEQYijI6hOiUiR+ISpF4heiUiR+ISpF4heiUlpt4DkyMhLur5fZV5GtMTo6Go7JYplFlY2LKv4yiyez8zL7J7MqM/swsvQyayg7V1a5l9mH0euZ5V5qA2aUWHqljTjbbODZj3Ppyi9EpUj8QlSKxC9EpUj8QlSKxC9EpbS62r98+XK2bt3aNZb144tWnCPnAPLec1lszZo1Cx6XbdeVrYgfP348jEXbXUHuSESrwNmqd8mqPeSv2enTp7seP3fuXDhm48aNYSxb3c7cijZ752U5lqzOZ7n343npyi9EpUj8QlSKxC9EpUj8QlSKxC9EpUj8QlRKq1bfsmXLwuKYzC6LYjt27AjH7N69O4zt2rUrjGX2YbTVVFagMzY2VpRHRmbzRAU82fZfGVkfuRLLMSswyoqIsuecjYt67pX22yuNZfNY0qMymseF9DrUlV+ISpH4hagUiV+ISpH4hagUiV+ISpH4haiUea0+M7sf+BAw5e5vaY5tAr4F7AFeBG539xPzPdayZcvCarXMNorstz179oRj9u7dG8ZuuOGGMJZV9UV2TWY1Zf0CM2sos8ROnIin+tixY12Pnzx5MhxT2u8ws2dLtqfKrK2MpVy5l43Lnlfp9mVz6eXK/3Xg1tcduxt43N1vBB5vfhZCLCHmFb+7PwH87nWHbwMeaG4/AHy4z3kJIQZM6Wf+7e5+5Stjr9DZsVcIsYRY9IKfdz6YhB9OzGyfmU2a2WT22VgI0S6l4j9qZuMAzf9T0R3dfb+7T7j7RLawJIRol1LxPwLc0dy+A/h+f9IRQrRFL1bfg8B7gC1m9jLwOeDzwMNmdifwG+D2Xk5mZqGtlDXVvP7667sez6riMhvwDW94Qxhbu3ZtGIusqMxGy5pcZpw9ezaMZTlGVmXWEDSqtISyyr0sllW3ZdZWiXUIZdVvWSzLo9QGjGLZmGwee2Ve8bv7x4LQ+xZ9diHE0NA3/ISoFIlfiEqR+IWoFIlfiEqR+IWolFYbeLp7aKNk1kVkbWXNNrNYVrmXWWIlVWdZ5VtmbWVWX9YUNHpuUfNRyO2rzOorabpaWuXY74q5UrJ9DTOy5z0sdOUXolIkfiEqReIXolIkfiEqReIXolIkfiEqpVX/YXZ2lunp6a6xzEaLLLFBNG4saYyYWV6ZNdRvGw1iSymz0UobcWb2VRTLxpT2e8hes5KKudLmmG02Eu0HuvILUSkSvxCVIvELUSkSvxCVIvELUSmtr/afPn26aywrqImKXLL+eFkschygrG9atrVWFitdHe53sUq2ul3aK66kh19pn75sXNQuPntdSuejtC9gybmy/Ht+/EU/ghBiSSLxC1EpEr8QlSLxC1EpEr8QlSLxC1EpvWzXdT/wIWDK3d/SHLsX+CRwrLnbPe7+6HyPNTs7y4ULF7rGMmsusvqyPnfReSC32LJYZK9k1mG/7Z/5iOyhzDYqta8yonkcxHPOiM63FIpwMks3sjcXYgP3cuX/OnBrl+Nfdvebm3/zCl8IcW0xr/jd/Qngdy3kIoRokcV85r/LzA6Y2f1mtrFvGQkhWqFU/F8F3gTcDBwBvhjd0cz2mdmkmU324yuJQoj+UCR+dz/q7pfdfRb4GnBLct/97j7h7hOl390WQvSfIvGb2ficHz8CHOxPOkKItujF6nsQeA+wxcxeBj4HvMfMbgYceBH4VC8nM7PQosg+EkSW3qlTp8IxpbHSnnURJXYN5PZb1uuupHdeRqktWkJJL75riTbnqh/M+xvh7h/rcvi+AeQihGgRfcNPiEqR+IWoFIlfiEqR+IWoFIlfiEpptYHnsmXLGBsb6xrLrJzI6jt27FjX4wBHjx4NY+vWrQtjmf22Zs2arsdLtq2C3LJbtWpV0bho661Sqy8js2ez7ddKxgy6meWgKbH6SqzDhZxHV34hKkXiF6JSJH4hKkXiF6JSJH4hKkXiF6JSWrX6RkZGWL9+fddYtKcaxFbfq6++Go45fPhwGIvsRsitkm3btnU9nlmHGaWVapnVF8VKrb4sx5KKxdLKt343Qs1yL52r0irNKJfS/QR7RVd+ISpF4heiUiR+ISpF4heiUiR+ISql1dX+0dFRtm7d2jV2/PjxcNyZM2e6Hs+264rGzBe77rrrwtjatWu7Ho8KfiBflS0tSMlWqku268ryKFmlzmJLoRdfKaXOSMSg+/7pyi9EpUj8QlSKxC9EpUj8QlSKxC9EpUj8QlRKL9t17QK+AWynsz3Xfnf/ipltAr4F7KGzZdft7n4ie6yRkRE2bNjQNTYzMxOOm56e7nq81EbLYpm9EvWYu3DhQjgms3iynnVtFrm0SenzulY2eS3NI3veJbZoZsH2Si+PcAn4rLvfBLwD+LSZ3QTcDTzu7jcCjzc/CyGWCPOK392PuPvTze0zwHPATuA24IHmbg8AHx5UkkKI/rOg9w5mtgd4G/AksN3djzShV+h8LBBCLBF6Fr+ZrQW+A3zG3U/PjXnnA03XDzVmts/MJs1sMvtsLIRol57Eb2ajdIT/TXf/bnP4qJmNN/FxYKrbWHff7+4T7j6RbUQhhGiXecVvnSXH+4Dn3P1Lc0KPAHc0t+8Avt//9IQQg6KXqr53Ah8HnjWzZ5pj9wCfBx42szuB3wC3z/dA7l5UyVbSU+38+fNh7NSpU2EsqjqEMksmy73UlsvmMOqFWGp9Zr0Vs1j03EqtvozM9opi2euS5Vjapy+LlVTvRXkspHpwXlW5+4+B6BHf1/OZhBDXFPqGnxCVIvELUSkSvxCVIvELUSkSvxCV0moDT3cP7aHM5olsksx2yeyTzKLKiOyhku2zoLyqr8S2K936qd9bRvWjGm0pkllwg27UGVHnKyGEkPiFqBWJX4hKkfiFqBSJX4hKkfiFqJRWrb7Z2VnOnTvXNVZSSZXZaNn+edGee5Dv1bdy5coF55FVj5VWevXbfstsqMxOzWLRnKxYsWLBY+ajpFK01HLMxpU294zGZa9lZBMvxDbUlV+ISpH4hagUiV+ISpH4hagUiV+ISmm9sCdamc1WNqMV+HXr1oVjNm3aFMY2b94cxtavXx/Gou7Dpb3bSlf7s7mKxmVjstX+0i2jIpcjcz8GsRVW9JjZmNK5L3UCovMNot/hXHTlF6JSJH4hKkXiF6JSJH4hKkXiF6JSJH4hKmVeq8/MdgHfoLMFtwP73f0rZnYv8EngWHPXe9z90eyxsh5+mRUSWX2ZZZdtu5WNGxsbC2P9tvoWsrVSr+NKHrOkQAfKi5ZKyGyvEjsyy6+kUGi+PPrdw6+V7bqAS8Bn3f1pMxsDnjKzx5rYl93973s+mxDimqGXvfqOAEea22fM7Dlg56ATE0IMlgW9NzOzPcDbgCebQ3eZ2QEzu9/MNvY5NyHEAOlZ/Ga2FvgO8Bl3Pw18FXgTcDOddwZfDMbtM7NJM5ucmZnpQ8pCiH7Qk/jNbJSO8L/p7t8FcPej7n7Z3WeBrwG3dBvr7vvdfcLdJ7IuLkKIdplX/NZZPrwPeM7dvzTn+Picu30EONj/9IQQg6KX1f53Ah8HnjWzZ5pj9wAfM7Ob6dh/LwKf6uWEkY2SWUqR1ZfZchs2bAhjGzfGyxNZ779+v3Mp3aap373zBmH1RY9ZaotmZBVuUawfVXELIXtuUS6D3tqsl9X+HwPdzMPU0xdCXNvoG35CVIrEL0SlSPxCVIrEL0SlSPxCVEqrDTwhrjrKLKXVq1d3PZ4128ysvqzxZ5ZHZL30u+Jsvjyi+YB4K7KskjHLI5urqMoR2rX6MqsyqiItsd6g3J7NKgVLGnj2A135hagUiV+ISpH4hagUiV+ISpH4hagUiV+ISmnV6hsZGQktuKhyD2LbrnQ/vsy+yqrfInuotHFjVhWX2XmZxblly5auxy9duhSOyayybdu2FeUR5Z895zYZRLPN0safbVcYXkFXfiEqReIXolIkfiEqReIXolIkfiEqReIXolJa9V1WrFjB7t27u8ayxpmRpTc+Pt71OOR79WUVf5mVE8WyCrHMRsu4cOFCGNu+fXsYi/ZGyOY3s7ZK7dSouWpmpbZpeWXWZxbLciyxibNYZh2W2opXnXfRjyCEWJJI/EJUisQvRKVI/EJUisQvRKXMu9pvZquAJ4CVzf2/7e6fM7M3Ag8Bm4GngI+7e7oN7+rVq3nzm9/cPZGk4CMqxNmxY0c4JitIybb5mp6eDmNRP7iMlStXhrFsBTgrmsnyiNyFrJiptIdfttof9RLMXufSXZwztyIic3VKXYdsXLY6X+oILZZervyvAe9197fS2Y77VjN7B/AF4Mvu/gfACeDOwaUphOg384rfO5xtfhxt/jnwXuDbzfEHgA8PJEMhxEDo6TO/mY00O/ROAY8BvwZOuvuVb0O8DOwcTIpCiEHQk/jd/bK73wzcANwC/GGvJzCzfWY2aWaTZ86cKUxTCNFvFrTa7+4ngR8BfwxsMLMrqzc3AIeCMfvdfcLdJ7KFNiFEu8wrfjPbamYbmturgfcDz9H5I/Bnzd3uAL4/qCSFEP2nl8KeceABMxuh88fiYXf/NzP7JfCQmf0t8J/AffM90OjoKDt3dl8ayOyaqCglKzrJrLKsX2Bmo0V2TemWXJkNmL1LKin4yLb/yqymbK4yGzB6bteK1VcyZlAMq4ffvOJ39wPA27ocf4HO538hxBJE3/ATolIkfiEqReIXolIkfiEqReIXolIsq27q+8nMjgG/aX7cArza2sljlMfVKI+rWWp57Hb3uIHlHFoV/1UnNpt094mhnFx5KA/lobf9QtSKxC9EpQxT/PuHeO65KI+rUR5X8/82j6F95hdCDBe97ReiUoYifjO71cz+28yeN7O7h5FDk8eLZvasmT1jZpMtnvd+M5sys4Nzjm0ys8fM7FfN/xuHlMe9ZnaomZNnzOyDLeSxy8x+ZGa/NLNfmNlfNMdbnZMkj1bnxMxWmdlPzeznTR5/0xx/o5k92ejmW2YW7w/WC+7e6j9ghE4bsL3ACuDnwE1t59Hk8iKwZQjnfTfwduDgnGN/B9zd3L4b+MKQ8rgX+MuW52MceHtzewz4H+CmtuckyaPVOQEMWNvcHgWeBN4BPAx8tDn+j8CfL+Y8w7jy3wI87+4veKfV90PAbUPIY2i4+xPA7153+DY6jVChpYaoQR6t4+5H3P3p5vYZOs1idtLynCR5tIp3GHjT3GGIfyfw0pyfh9n804EfmtlTZrZvSDlcYbu7H2luvwLEW/EOnrvM7EDzsWDgHz/mYmZ76PSPeJIhzsnr8oCW56SNprm1L/i9y93fDvwp8Gkze/ewE4LOX346f5iGwVeBN9HZo+EI8MW2Tmxma4HvAJ9x99NzY23OSZc8Wp8TX0TT3F4ZhvgPAbvm/Bw2/xw07n6o+X8K+B7D7Ux01MzGAZr/p4aRhLsfbX7xZoGv0dKcmNkoHcF9092/2xxufU665TGsOWnOveCmub0yDPH/DLixWblcAXwUeKTtJMxsjZmNXbkNfAA4mI8aKI/QaYQKQ2yIekVsDR+hhTmxTkO9+4Dn3P1Lc0KtzkmUR9tz0lrT3LZWMF+3mvlBOiupvwb+akg57KXjNPwc+EWbeQAP0nn7eJHOZ7c76ex5+DjwK+A/gE1DyuOfgWeBA3TEN95CHu+i85b+APBM8++Dbc9JkkercwL8EZ2muAfo/KH56zm/sz8Fngf+FVi5mPPoG35CVErtC35CVIvEL0SlSPxCVIrEL0SlSPxCVIrEL0SlSPxCVIrEL0Sl/C+NV52vOIpKdgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digit: 1\n"
     ]
    }
   ],
   "source": [
    "example = np.random.choice(np.arange(n_train))\n",
    "\n",
    "image = training_set_gs[example]\n",
    "label = training_labels[example][0]\n",
    "\n",
    "if label == 10:\n",
    "    label = 0\n",
    "\n",
    "plt.imshow(np.squeeze(image), cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "print(\"Digit: {}\".format(label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't flatten the inputs! Use a CNN to process the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_set_flat = training_set_gs.reshape((n_train, -1))\n",
    "# test_set_flat = test_set_gs.reshape((n_test, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode the labels as one-hot vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(labels):\n",
    "    \"\"\"\n",
    "    Encodes the labels as one-hot vectors. Zero is represented as 10 in SVHN.\n",
    "    [10] -> [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    [2] -> [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "    \n",
    "    \"\"\"\n",
    "    labels = np.squeeze(labels)\n",
    "    one_hot_labels = []\n",
    "    for num in labels:\n",
    "        one_hot = [0.0] * 10\n",
    "        if num == 10:\n",
    "            one_hot[0] = 1.0\n",
    "        else:\n",
    "            one_hot[num] = 1.0\n",
    "        one_hot_labels.append(one_hot)\n",
    "    labels = np.array(one_hot_labels).astype(np.float32)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_labels_one_hot = one_hot(training_labels)\n",
    "test_labels_one_hot = one_hot(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26032, 10)\n",
      "(26032, 10)\n"
     ]
    }
   ],
   "source": [
    "print(training_labels_one_hot.shape)\n",
    "print(test_labels_one_hot.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVHN_CNN:\n",
    "    def __init__(self, wd_factor, learning_rate):\n",
    "        self.wd_factor = wd_factor\n",
    "        self.learning_rate = learning_rate\n",
    "        self.train_pointer = 0\n",
    "        self.test_pointer = 0\n",
    "        \n",
    "        self.input = tf.placeholder(dtype=tf.float32, shape=[None, 32, 32, 1], name='input')\n",
    "        self.ground_truth = tf.placeholder(dtype=tf.float32, shape=[None, 10], name='ground_truth')\n",
    "        \n",
    "        # For batch norm and dropout\n",
    "        self.is_training = tf.placeholder(tf.bool, name='is_training')\n",
    "        print(self.input)\n",
    "        \n",
    "        self._build_graph()\n",
    "        \n",
    "    def _build_graph(self):\n",
    "        weights = []  # for weight decay\n",
    "        \n",
    "        with tf.variable_scope('layers'):\n",
    "            h = tf.layers.conv2d(self.input, 32, (11, 11), strides=(4, 4), padding='same', \n",
    "                                 data_format='channels_last', activation=None, use_bias=True,\n",
    "                                 kernel_initializer=tf.glorot_uniform_initializer(), name='conv1')\n",
    "            print(h)\n",
    "            \n",
    "            h = tf.layers.batch_normalization(h, training=self.is_training)\n",
    "            h = tf.nn.relu(h)\n",
    "            h = tf.layers.conv2d(h, 64, (5, 5), strides=(1, 1), padding='same', \n",
    "                                 data_format='channels_last', activation=None, use_bias=True,\n",
    "                                 kernel_initializer=tf.glorot_uniform_initializer(), name='conv2')\n",
    "            \n",
    "            h = tf.layers.batch_normalization(h, training=self.is_training)\n",
    "            h = tf.nn.relu(h)\n",
    "            h = tf.layers.conv2d(h, 64, (3, 3), strides=(1, 1), padding='same', \n",
    "                                 data_format='channels_last', activation=None, use_bias=True,\n",
    "                                 kernel_initializer=tf.glorot_uniform_initializer(), name='conv3')\n",
    "            \n",
    "            # Downsample\n",
    "            h = tf.layers.max_pooling2d(h, (2, 2), (2, 2), padding='valid', name='pool1')\n",
    "            print(h)\n",
    "            \n",
    "            # Fully connected layers\n",
    "            h = tf.layers.batch_normalization(h, training=self.is_training)\n",
    "            h = tf.nn.relu(h)\n",
    "            h = tf.layers.flatten(h)\n",
    "            print(h)\n",
    "            \n",
    "            h = tf.layers.dense(h, 32, kernel_initializer=tf.glorot_uniform_initializer(), \n",
    "                                activation=tf.nn.relu, name='dense1')\n",
    "            print(h)\n",
    "            h = tf.layers.dropout(h, rate=0.25, training=self.is_training, name='dropout1')\n",
    "            print(h)\n",
    "            \n",
    "            self.logits = tf.layers.dense(h, 10, kernel_initializer=tf.glorot_uniform_initializer(), \n",
    "                                          activation=tf.identity, name='dense2')\n",
    "            print(self.logits)\n",
    "            self.prediction = tf.nn.softmax(self.logits, name='softmax_prediction')\n",
    "            \n",
    "        with tf.name_scope('loss'):\n",
    "            self.loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=self.logits, \n",
    "                                                                                  labels=self.ground_truth))\n",
    "            self.loss += self.weight_decay()\n",
    "            \n",
    "        self.optimizer = tf.train.AdamOptimizer(self.learning_rate)\n",
    "        \n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(update_ops):\n",
    "            self.train_op = self.optimizer.minimize(self.loss)\n",
    "            \n",
    "    def weight_decay(self):\n",
    "        loss = 0\n",
    "        for v in tf.global_variables():\n",
    "            if 'Adam' in v.name:\n",
    "                continue\n",
    "            elif 'kernel' in v.name:\n",
    "                loss += self.wd_factor * tf.nn.l2_loss(v)\n",
    "        print(loss)\n",
    "        return loss\n",
    "    \n",
    "    def train_minibatch(self, samples, labels, batch_size):\n",
    "        if self.train_pointer + batch_size <= samples.shape[0]:\n",
    "            samples_minibatch = samples[self.train_pointer: self.train_pointer + batch_size]\n",
    "            labels_minibatch = labels[self.train_pointer: self.train_pointer + batch_size]\n",
    "            self.train_pointer += batch_size\n",
    "        else:\n",
    "            samples_minibatch = samples[self.train_pointer:]\n",
    "            labels_minibatch = labels[self.train_pointer: self.train_pointer + batch_size]\n",
    "            self.train_pointer = 0\n",
    "        return samples_minibatch, labels_minibatch\n",
    "\n",
    "    def train(self, train_samples, train_labels, train_batch_size, iteration_steps):\n",
    "        print('Start Training')\n",
    "        losses = []\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            saver = tf.train.Saver()\n",
    "            \n",
    "            for i in range(iteration_steps):\n",
    "                samples, labels = self.train_minibatch(train_samples, train_labels, train_batch_size)\n",
    "                \n",
    "                feed_dict = {self.input: samples, self.ground_truth: labels, self.is_training: True}\n",
    "                _, loss = sess.run([self.train_op, self.loss], feed_dict=feed_dict)\n",
    "                \n",
    "                if i % 50 == 0:\n",
    "                    print(\"Minibatch loss at step {}: {}\".format(i, loss))\n",
    "                    losses.append([i, loss])\n",
    "                    \n",
    "            saver.save(sess, './model')\n",
    "        return losses\n",
    "                    \n",
    "    def test_minibatch(self, samples, labels, batch_size):\n",
    "        if self.test_pointer + batch_size <= samples.shape[0]:\n",
    "            samples_minibatch = samples[self.test_pointer: self.test_pointer + batch_size]\n",
    "            labels_minibatch = labels[self.test_pointer: self.test_pointer + batch_size]\n",
    "            self.test_pointer += batch_size\n",
    "            end_of_epoch = False\n",
    "        else:\n",
    "            samples_minibatch = samples[self.test_pointer:]\n",
    "            labels_minibatch = labels[self.test_pointer: self.test_pointer + batch_size]\n",
    "            self.test_pointer = 0\n",
    "            end_of_epoch = True\n",
    "        return samples_minibatch, labels_minibatch, end_of_epoch\n",
    "            \n",
    "    def test(self, test_samples, test_labels, test_batch_size):\n",
    "        self.test_pointer = 0\n",
    "        end_of_epoch = False\n",
    "        losses = []\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            saver = tf.train.import_meta_graph(\"./model.meta\")\n",
    "            saver.restore(sess, './model')\n",
    "            while not end_of_epoch:\n",
    "                samples, labels, end_of_epoch = self.test_minibatch(test_samples, test_labels, test_batch_size)\n",
    "                feed_dict = {self.input: samples, self.ground_truth: labels, self.is_training: False}\n",
    "                losses.append(sess.run(self.loss, feed_dict=feed_dict))  \n",
    "        print(\"Average test loss: {}\".format(np.mean(losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input:0\", shape=(?, 32, 32, 1), dtype=float32)\n",
      "Tensor(\"layers/conv1/BiasAdd:0\", shape=(?, 8, 8, 32), dtype=float32)\n",
      "Tensor(\"layers/pool1/MaxPool:0\", shape=(?, 4, 4, 64), dtype=float32)\n",
      "Tensor(\"layers/flatten/Reshape:0\", shape=(?, 1024), dtype=float32)\n",
      "Tensor(\"layers/dense1/Relu:0\", shape=(?, 32), dtype=float32)\n",
      "Tensor(\"layers/dropout1/cond/Merge:0\", shape=(?, 32), dtype=float32)\n",
      "Tensor(\"layers/dense2/Identity:0\", shape=(?, 10), dtype=float32)\n",
      "Tensor(\"loss/add_4:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "WD_FACTOR = 0.0\n",
    "LEARNING_RATE = 0.001\n",
    "model = SVHN_CNN(WD_FACTOR, LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'layers/conv1/kernel:0' shape=(11, 11, 1, 32) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv1/bias:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization/gamma:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization/beta:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization/moving_mean:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization/moving_variance:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv2/kernel:0' shape=(5, 5, 32, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv2/bias:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_1/gamma:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_1/beta:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_1/moving_mean:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_1/moving_variance:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv3/kernel:0' shape=(3, 3, 64, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv3/bias:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_2/gamma:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_2/beta:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_2/moving_mean:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_2/moving_variance:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/dense1/kernel:0' shape=(1024, 32) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/dense1/bias:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/dense2/kernel:0' shape=(32, 10) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/dense2/bias:0' shape=(10,) dtype=float32_ref>,\n",
       " <tf.Variable 'beta1_power:0' shape=() dtype=float32_ref>,\n",
       " <tf.Variable 'beta2_power:0' shape=() dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv1/kernel/Adam:0' shape=(11, 11, 1, 32) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv1/kernel/Adam_1:0' shape=(11, 11, 1, 32) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv1/bias/Adam:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv1/bias/Adam_1:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization/gamma/Adam:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization/gamma/Adam_1:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization/beta/Adam:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization/beta/Adam_1:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv2/kernel/Adam:0' shape=(5, 5, 32, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv2/kernel/Adam_1:0' shape=(5, 5, 32, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv2/bias/Adam:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv2/bias/Adam_1:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_1/gamma/Adam:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_1/gamma/Adam_1:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_1/beta/Adam:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_1/beta/Adam_1:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv3/kernel/Adam:0' shape=(3, 3, 64, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv3/kernel/Adam_1:0' shape=(3, 3, 64, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv3/bias/Adam:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv3/bias/Adam_1:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_2/gamma/Adam:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_2/gamma/Adam_1:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_2/beta/Adam:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_2/beta/Adam_1:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/dense1/kernel/Adam:0' shape=(1024, 32) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/dense1/kernel/Adam_1:0' shape=(1024, 32) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/dense1/bias/Adam:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/dense1/bias/Adam_1:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/dense2/kernel/Adam:0' shape=(32, 10) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/dense2/kernel/Adam_1:0' shape=(32, 10) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/dense2/bias/Adam:0' shape=(10,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/dense2/bias/Adam_1:0' shape=(10,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.global_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training\n",
      "Minibatch loss at step 0: 2.820195198059082\n",
      "Minibatch loss at step 50: 2.0125513076782227\n",
      "Minibatch loss at step 100: 1.5967533588409424\n",
      "Minibatch loss at step 150: 1.384171962738037\n",
      "Minibatch loss at step 200: 0.8257154226303101\n",
      "Minibatch loss at step 250: 0.9801850318908691\n",
      "Minibatch loss at step 300: 0.6712011098861694\n",
      "Minibatch loss at step 350: 0.837364912033081\n",
      "Minibatch loss at step 400: 0.6939016580581665\n",
      "Minibatch loss at step 450: 0.6222531199455261\n",
      "Minibatch loss at step 500: 0.4839797616004944\n",
      "Minibatch loss at step 550: 0.4917047619819641\n",
      "Minibatch loss at step 600: 0.4551682770252228\n",
      "Minibatch loss at step 650: 0.410694420337677\n",
      "Minibatch loss at step 700: 0.45878463983535767\n",
      "Minibatch loss at step 750: 0.5939524173736572\n",
      "Minibatch loss at step 800: 0.43253767490386963\n",
      "Minibatch loss at step 850: 0.2575885057449341\n",
      "Minibatch loss at step 900: 0.4486636221408844\n",
      "Minibatch loss at step 950: 0.42629319429397583\n",
      "Minibatch loss at step 1000: 0.5832847952842712\n",
      "Minibatch loss at step 1050: 0.5888002514839172\n",
      "Minibatch loss at step 1100: 0.40039077401161194\n",
      "Minibatch loss at step 1150: 0.27169957756996155\n",
      "Minibatch loss at step 1200: 0.37998902797698975\n",
      "Minibatch loss at step 1250: 0.19600598514080048\n",
      "Minibatch loss at step 1300: 0.3473309874534607\n",
      "Minibatch loss at step 1350: 0.2988717555999756\n",
      "Minibatch loss at step 1400: 0.3406512141227722\n",
      "Minibatch loss at step 1450: 0.3095782697200775\n",
      "Minibatch loss at step 1500: 0.2448464184999466\n",
      "Minibatch loss at step 1550: 0.2937709093093872\n",
      "Minibatch loss at step 1600: 0.27162474393844604\n",
      "Minibatch loss at step 1650: 0.24574166536331177\n",
      "Minibatch loss at step 1700: 0.2482462227344513\n",
      "Minibatch loss at step 1750: 0.25437891483306885\n",
      "Minibatch loss at step 1800: 0.18843403458595276\n",
      "Minibatch loss at step 1850: 0.21977633237838745\n",
      "Minibatch loss at step 1900: 0.4564451575279236\n",
      "Minibatch loss at step 1950: 0.16809092462062836\n",
      "Minibatch loss at step 2000: 0.15097713470458984\n",
      "Minibatch loss at step 2050: 0.30923107266426086\n",
      "Minibatch loss at step 2100: 0.14919668436050415\n",
      "Minibatch loss at step 2150: 0.19761884212493896\n",
      "Minibatch loss at step 2200: 0.2279263287782669\n",
      "Minibatch loss at step 2250: 0.24371230602264404\n",
      "Minibatch loss at step 2300: 0.16977673768997192\n",
      "Minibatch loss at step 2350: 0.16409868001937866\n",
      "Minibatch loss at step 2400: 0.13410033285617828\n",
      "Minibatch loss at step 2450: 0.21413558721542358\n",
      "Minibatch loss at step 2500: 0.17299482226371765\n",
      "Minibatch loss at step 2550: 0.16134952008724213\n",
      "Minibatch loss at step 2600: 0.1584310233592987\n",
      "Minibatch loss at step 2650: 0.1329353153705597\n",
      "Minibatch loss at step 2700: 0.10308094322681427\n",
      "Minibatch loss at step 2750: 0.33746033906936646\n",
      "Minibatch loss at step 2800: 0.17212504148483276\n",
      "Minibatch loss at step 2850: 0.15941374003887177\n",
      "Minibatch loss at step 2900: 0.13630551099777222\n",
      "Minibatch loss at step 2950: 0.1498984843492508\n",
      "Minibatch loss at step 3000: 0.15859052538871765\n",
      "Minibatch loss at step 3050: 0.14230427145957947\n",
      "Minibatch loss at step 3100: 0.12319192290306091\n",
      "Minibatch loss at step 3150: 0.131905198097229\n",
      "Minibatch loss at step 3200: 0.11587994545698166\n",
      "Minibatch loss at step 3250: 0.13928905129432678\n",
      "Minibatch loss at step 3300: 0.08104598522186279\n",
      "Minibatch loss at step 3350: 0.16012631356716156\n",
      "Minibatch loss at step 3400: 0.06982622295618057\n",
      "Minibatch loss at step 3450: 0.1531408429145813\n",
      "Minibatch loss at step 3500: 0.07218104600906372\n",
      "Minibatch loss at step 3550: 0.15828053653240204\n",
      "Minibatch loss at step 3600: 0.15405946969985962\n",
      "Minibatch loss at step 3650: 0.12437707185745239\n",
      "Minibatch loss at step 3700: 0.12890766561031342\n",
      "Minibatch loss at step 3750: 0.16518166661262512\n",
      "Minibatch loss at step 3800: 0.07390251755714417\n",
      "Minibatch loss at step 3850: 0.20563223958015442\n",
      "Minibatch loss at step 3900: 0.05848206579685211\n",
      "Minibatch loss at step 3950: 0.11445572227239609\n",
      "Minibatch loss at step 4000: 0.07888725399971008\n",
      "Minibatch loss at step 4050: 0.1491493582725525\n",
      "Minibatch loss at step 4100: 0.07835476100444794\n",
      "Minibatch loss at step 4150: 0.09137678891420364\n",
      "Minibatch loss at step 4200: 0.12102681398391724\n",
      "Minibatch loss at step 4250: 0.14995771646499634\n",
      "Minibatch loss at step 4300: 0.059636060148477554\n",
      "Minibatch loss at step 4350: 0.0737781673669815\n",
      "Minibatch loss at step 4400: 0.19954349100589752\n",
      "Minibatch loss at step 4450: 0.06580032408237457\n",
      "Minibatch loss at step 4500: 0.13717210292816162\n",
      "Minibatch loss at step 4550: 0.0843973457813263\n",
      "Minibatch loss at step 4600: 0.09096422791481018\n",
      "Minibatch loss at step 4650: 0.13600817322731018\n",
      "Minibatch loss at step 4700: 0.07478553056716919\n",
      "Minibatch loss at step 4750: 0.07700102031230927\n",
      "Minibatch loss at step 4800: 0.1256508082151413\n",
      "Minibatch loss at step 4850: 0.1379404067993164\n",
      "Minibatch loss at step 4900: 0.16989421844482422\n",
      "Minibatch loss at step 4950: 0.027889182791113853\n",
      "Minibatch loss at step 5000: 0.06298340111970901\n",
      "Minibatch loss at step 5050: 0.08212532103061676\n",
      "Minibatch loss at step 5100: 0.08355933427810669\n",
      "Minibatch loss at step 5150: 0.20051515102386475\n",
      "Minibatch loss at step 5200: 0.08384372293949127\n",
      "Minibatch loss at step 5250: 0.11461574584245682\n",
      "Minibatch loss at step 5300: 0.1418282389640808\n",
      "Minibatch loss at step 5350: 0.06392177939414978\n",
      "Minibatch loss at step 5400: 0.014676038175821304\n",
      "Minibatch loss at step 5450: 0.12853284180164337\n",
      "Minibatch loss at step 5500: 0.15874452888965607\n",
      "Minibatch loss at step 5550: 0.0522882342338562\n",
      "Minibatch loss at step 5600: 0.10986867547035217\n",
      "Minibatch loss at step 5650: 0.04296416789293289\n",
      "Minibatch loss at step 5700: 0.08457975834608078\n",
      "Minibatch loss at step 5750: 0.06408768147230148\n",
      "Minibatch loss at step 5800: 0.04922439157962799\n",
      "Minibatch loss at step 5850: 0.10034327954053879\n",
      "Minibatch loss at step 5900: 0.07257796078920364\n",
      "Minibatch loss at step 5950: 0.06103147938847542\n",
      "Minibatch loss at step 6000: 0.08105581998825073\n",
      "Minibatch loss at step 6050: 0.07449780404567719\n",
      "Minibatch loss at step 6100: 0.19422151148319244\n",
      "Minibatch loss at step 6150: 0.04258687049150467\n",
      "Minibatch loss at step 6200: 0.036662597209215164\n",
      "Minibatch loss at step 6250: 0.0513903871178627\n",
      "Minibatch loss at step 6300: 0.06798078864812851\n",
      "Minibatch loss at step 6350: 0.038565151393413544\n",
      "Minibatch loss at step 6400: 0.06909382343292236\n",
      "Minibatch loss at step 6450: 0.03619840741157532\n",
      "Minibatch loss at step 6500: 0.11830729991197586\n",
      "Minibatch loss at step 6550: 0.07803787291049957\n",
      "Minibatch loss at step 6600: 0.05074123665690422\n",
      "Minibatch loss at step 6650: 0.06077967956662178\n",
      "Minibatch loss at step 6700: 0.04618047550320625\n",
      "Minibatch loss at step 6750: 0.05986621230840683\n",
      "Minibatch loss at step 6800: 0.061794180423021317\n",
      "Minibatch loss at step 6850: 0.07461091876029968\n",
      "Minibatch loss at step 6900: 0.021582677960395813\n",
      "Minibatch loss at step 6950: 0.07260787487030029\n",
      "Minibatch loss at step 7000: 0.13034948706626892\n",
      "Minibatch loss at step 7050: 0.02952020987868309\n",
      "Minibatch loss at step 7100: 0.060491207987070084\n",
      "Minibatch loss at step 7150: 0.14707428216934204\n",
      "Minibatch loss at step 7200: 0.07083351165056229\n",
      "Minibatch loss at step 7250: 0.0683763399720192\n",
      "Minibatch loss at step 7300: 0.014621417969465256\n",
      "Minibatch loss at step 7350: 0.06038656085729599\n",
      "Minibatch loss at step 7400: 0.08722348511219025\n",
      "Minibatch loss at step 7450: 0.10089953988790512\n",
      "Minibatch loss at step 7500: 0.026829848065972328\n",
      "Minibatch loss at step 7550: 0.08780242502689362\n",
      "Minibatch loss at step 7600: 0.042874179780483246\n",
      "Minibatch loss at step 7650: 0.05939727649092674\n",
      "Minibatch loss at step 7700: 0.06665165722370148\n",
      "Minibatch loss at step 7750: 0.03218276798725128\n",
      "Minibatch loss at step 7800: 0.02512218989431858\n",
      "Minibatch loss at step 7850: 0.06224671006202698\n",
      "Minibatch loss at step 7900: 0.05327371880412102\n",
      "Minibatch loss at step 7950: 0.0713629350066185\n",
      "Minibatch loss at step 8000: 0.03711334615945816\n",
      "Minibatch loss at step 8050: 0.09374430030584335\n",
      "Minibatch loss at step 8100: 0.049644552171230316\n",
      "Minibatch loss at step 8150: 0.04769221693277359\n",
      "Minibatch loss at step 8200: 0.05003710091114044\n",
      "Minibatch loss at step 8250: 0.04631464183330536\n",
      "Minibatch loss at step 8300: 0.04960988834500313\n",
      "Minibatch loss at step 8350: 0.056409627199172974\n",
      "Minibatch loss at step 8400: 0.04135742783546448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minibatch loss at step 8450: 0.05331205204129219\n",
      "Minibatch loss at step 8500: 0.03009815141558647\n",
      "Minibatch loss at step 8550: 0.02700187638401985\n",
      "Minibatch loss at step 8600: 0.057766493409872055\n",
      "Minibatch loss at step 8650: 0.04166650399565697\n",
      "Minibatch loss at step 8700: 0.06636607646942139\n",
      "Minibatch loss at step 8750: 0.05299738049507141\n",
      "Minibatch loss at step 8800: 0.08094996958971024\n",
      "Minibatch loss at step 8850: 0.03088223934173584\n",
      "Minibatch loss at step 8900: 0.04179678112268448\n",
      "Minibatch loss at step 8950: 0.07604600489139557\n",
      "Minibatch loss at step 9000: 0.04877077043056488\n",
      "Minibatch loss at step 9050: 0.05550263822078705\n",
      "Minibatch loss at step 9100: 0.03666957840323448\n",
      "Minibatch loss at step 9150: 0.08914261311292648\n",
      "Minibatch loss at step 9200: 0.07807178795337677\n",
      "Minibatch loss at step 9250: 0.07959960401058197\n",
      "Minibatch loss at step 9300: 0.021194254979491234\n",
      "Minibatch loss at step 9350: 0.034996483474969864\n",
      "Minibatch loss at step 9400: 0.023452825844287872\n",
      "Minibatch loss at step 9450: 0.04015667736530304\n",
      "Minibatch loss at step 9500: 0.03499769791960716\n",
      "Minibatch loss at step 9550: 0.029064428061246872\n",
      "Minibatch loss at step 9600: 0.11672435700893402\n",
      "Minibatch loss at step 9650: 0.019904710352420807\n",
      "Minibatch loss at step 9700: 0.042342789471149445\n",
      "Minibatch loss at step 9750: 0.06533005833625793\n",
      "Minibatch loss at step 9800: 0.02570880390703678\n",
      "Minibatch loss at step 9850: 0.0550195574760437\n",
      "Minibatch loss at step 9900: 0.02189340442419052\n",
      "Minibatch loss at step 9950: 0.05235402286052704\n",
      "Training time: 668.1005680561066s\n"
     ]
    }
   ],
   "source": [
    "TRAIN_BATCH_SIZE = 128\n",
    "ITERATIONS = 10000\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "losses = model.train(training_set_gs, training_labels_one_hot, TRAIN_BATCH_SIZE, ITERATIONS)\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Training time: {}s\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 2)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    losses = np.array(losses)\n",
    "    np.save('./train_losses.npy', losses)\n",
    "    print(losses.shape)\n",
    "except NameError:\n",
    "    losses = np.load('./train_losses.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "iterations = losses[:, 0]\n",
    "train_loss = losses[:, 1]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(iterations, train_loss, 'b-')\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test network predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "Average test loss: 0.012347172014415264\n"
     ]
    }
   ],
   "source": [
    "TEST_BATCH_SIZE = 128\n",
    "\n",
    "model.test(test_set_gs, test_labels_one_hot, TEST_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "Test sample digit: 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1224x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network prediction probabilities:\n",
      "[1.9132730e-10 3.1806036e-07 2.6779470e-10 1.6342399e-12 4.0062177e-15\n",
      " 6.0741006e-13 4.3749831e-14 9.9999964e-01 4.9858375e-15 4.1796779e-12]\n"
     ]
    }
   ],
   "source": [
    "example = np.random.choice(np.arange(n_test))\n",
    "\n",
    "sample = np.expand_dims(test_set_gs[example], axis=0)\n",
    "label = np.expand_dims(test_labels_one_hot[example], axis=0)\n",
    "\n",
    "digit = np.where(label[0]==1.0)[0][0]\n",
    "\n",
    "feed_dict = {model.input: sample, model.ground_truth: label, model.is_training: False}\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver = tf.train.import_meta_graph(\"./model.meta\")\n",
    "    saver.restore(sess, './model')\n",
    "    prediction = sess.run(model.prediction, feed_dict=feed_dict)[0]\n",
    "\n",
    "image = np.reshape(sample, (32, 32))\n",
    "\n",
    "print(\"Test sample digit: {}\".format(digit))\n",
    "fig, ax = plt.subplots(1, 2, figsize=(17, 5))\n",
    "ax[0].imshow(image, cmap='gray')\n",
    "ax[0].set_title(\"Test example\")\n",
    "\n",
    "classes = np.arange(10)\n",
    "width = 1.0\n",
    "\n",
    "#fig, ax = plt.subplots()\n",
    "ax[1].bar(classes, prediction, width, color='Blue')\n",
    "ax[1].set_ylabel('Probabilities')\n",
    "ax[1].set_title('Network categorical distribution')\n",
    "ax[1].set_xticks(classes)\n",
    "ax[1].set_xticklabels(('0', '1', '2', '3', '4', '5', '6', '7', '8', '9'))\n",
    "ax[1].set_xlabel('Digit class')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"Network prediction probabilities:\")\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
=======
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Week 3: CNN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVHN can be downloaded from http://ufldl.stanford.edu/housenumbers/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "\n",
    "train = loadmat('../SVHN/train_32x32.mat')\n",
    "test = loadmat('../SVHN/test_32x32.mat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`train` and `test` are dictionaries with keys `'X'` and `'y'`. The values are numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train['X'].shape)\n",
    "print(train['y'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test['X'].shape)\n",
    "print(test['y'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "training_set = np.transpose(train['X'], (3, 0, 1, 2)).astype(np.float32)\n",
    "training_labels = train['y']\n",
    "\n",
    "test_set = np.transpose(test['X'], (3, 0, 1, 2)).astype(np.float32)\n",
    "test_labels = test['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_train = training_set.shape[0]\n",
    "n_test = test_set.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = np.random.choice(np.arange(n_train))\n",
    "\n",
    "image = training_set[example]\n",
    "label = training_labels[example][0]\n",
    "\n",
    "if label == 10:\n",
    "    label = 0\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "\n",
    "print(\"Digit: {}\".format(label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the images to grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_to_grayscale(images):\n",
    "    images = np.add.reduce(images, keepdims=True, axis=3)\n",
    "    images = images / 3.0\n",
    "    return images / 128.0 - 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_set_gs = convert_to_grayscale(training_set)\n",
    "test_set_gs = convert_to_grayscale(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(training_set_gs.shape)\n",
    "print(test_set_gs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = np.random.choice(np.arange(n_train))\n",
    "\n",
    "image = training_set_gs[example]\n",
    "label = training_labels[example][0]\n",
    "\n",
    "if label == 10:\n",
    "    label = 0\n",
    "\n",
    "plt.imshow(np.squeeze(image), cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "print(\"Digit: {}\".format(label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't flatten the inputs! Use a CNN to process the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# training_set_flat = training_set_gs.reshape((n_train, -1))\n",
    "# test_set_flat = test_set_gs.reshape((n_test, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode the labels as one-hot vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot(labels):\n",
    "    \"\"\"\n",
    "    Encodes the labels as one-hot vectors. Zero is represented as 10 in SVHN.\n",
    "    [10] -> [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    [2] -> [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "    \n",
    "    \"\"\"\n",
    "    labels = np.squeeze(labels)\n",
    "    one_hot_labels = []\n",
    "    for num in labels:\n",
    "        one_hot = [0.0] * 10\n",
    "        if num == 10:\n",
    "            one_hot[0] = 1.0\n",
    "        else:\n",
    "            one_hot[num] = 1.0\n",
    "        one_hot_labels.append(one_hot)\n",
    "    labels = np.array(one_hot_labels).astype(np.float32)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_labels_one_hot = one_hot(training_labels)\n",
    "test_labels_one_hot = one_hot(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(training_labels_one_hot.shape)\n",
    "print(test_labels_one_hot.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SVHN_CNN:\n",
    "    def __init__(self, wd_factor, learning_rate):\n",
    "        self.wd_factor = wd_factor\n",
    "        self.learning_rate = learning_rate\n",
    "        self.train_pointer = 0\n",
    "        self.test_pointer = 0\n",
    "        \n",
    "        self.input = tf.placeholder(dtype=tf.float32, shape=[None, 32, 32, 1], name='input')\n",
    "        self.ground_truth = tf.placeholder(dtype=tf.float32, shape=[None, 10], name='ground_truth')\n",
    "        \n",
    "        # For batch norm and dropout\n",
    "        self.is_training = tf.placeholder(tf.bool, name='is_training')\n",
    "        print(self.input)\n",
    "        \n",
    "        self._build_graph()\n",
    "        \n",
    "    def _build_graph(self):\n",
    "        weights = []  # for weight decay\n",
    "        \n",
    "        with tf.variable_scope('layers'):\n",
    "            h = tf.layers.conv2d(self.input, 32, (11, 11), strides=(4, 4), padding='same', \n",
    "                                 data_format='channels_last', activation=None, use_bias=True,\n",
    "                                 kernel_initializer=tf.glorot_uniform_initializer(), name='conv1')\n",
    "            print(h)\n",
    "            \n",
    "            h = tf.layers.batch_normalization(h, training=self.is_training)\n",
    "            h = tf.nn.relu(h)\n",
    "            h = tf.layers.conv2d(h, 64, (5, 5), strides=(1, 1), padding='same', \n",
    "                                 data_format='channels_last', activation=None, use_bias=True,\n",
    "                                 kernel_initializer=tf.glorot_uniform_initializer(), name='conv2')\n",
    "            \n",
    "            h = tf.layers.batch_normalization(h, training=self.is_training)\n",
    "            h = tf.nn.relu(h)\n",
    "            h = tf.layers.conv2d(h, 64, (3, 3), strides=(1, 1), padding='same', \n",
    "                                 data_format='channels_last', activation=None, use_bias=True,\n",
    "                                 kernel_initializer=tf.glorot_uniform_initializer(), name='conv3')\n",
    "            \n",
    "            # Downsample\n",
    "            h = tf.layers.max_pooling2d(h, (2, 2), (2, 2), padding='valid', name='pool1')\n",
    "            print(h)\n",
    "            \n",
    "            # Fully connected layers\n",
    "            h = tf.layers.batch_normalization(h, training=self.is_training)\n",
    "            h = tf.nn.relu(h)\n",
    "            h = tf.layers.flatten(h)\n",
    "            print(h)\n",
    "            \n",
    "            h = tf.layers.dense(h, 32, kernel_initializer=tf.glorot_uniform_initializer(), \n",
    "                                activation=tf.nn.relu, name='dense1')\n",
    "            print(h)\n",
    "            h = tf.layers.dropout(h, rate=0.25, training=self.is_training, name='dropout1')\n",
    "            print(h)\n",
    "            \n",
    "            self.logits = tf.layers.dense(h, 10, kernel_initializer=tf.glorot_uniform_initializer(), \n",
    "                                          activation=tf.identity, name='dense2')\n",
    "            print(self.logits)\n",
    "            self.prediction = tf.nn.softmax(self.logits, name='softmax_prediction')\n",
    "            \n",
    "        with tf.name_scope('loss'):\n",
    "            self.loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=self.logits, \n",
    "                                                                                  labels=self.ground_truth))\n",
    "            self.loss += self.weight_decay()\n",
    "            \n",
    "        self.optimizer = tf.train.AdamOptimizer(self.learning_rate)\n",
    "        \n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(update_ops):\n",
    "            self.train_op = self.optimizer.minimize(self.loss)\n",
    "            \n",
    "    def weight_decay(self):\n",
    "        loss = 0\n",
    "        for v in tf.global_variables():\n",
    "            if 'Adam' in v.name:\n",
    "                continue\n",
    "            elif 'kernel' in v.name:\n",
    "                loss += self.wd_factor * tf.nn.l2_loss(v)\n",
    "        print(loss)\n",
    "        return loss\n",
    "    \n",
    "    def train_minibatch(self, samples, labels, batch_size):\n",
    "        if self.train_pointer + batch_size <= samples.shape[0]:\n",
    "            samples_minibatch = samples[self.train_pointer: self.train_pointer + batch_size]\n",
    "            labels_minibatch = labels[self.train_pointer: self.train_pointer + batch_size]\n",
    "            self.train_pointer += batch_size\n",
    "        else:\n",
    "            samples_minibatch = samples[self.train_pointer:]\n",
    "            labels_minibatch = labels[self.train_pointer: self.train_pointer + batch_size]\n",
    "            self.train_pointer = 0\n",
    "        return samples_minibatch, labels_minibatch\n",
    "\n",
    "    def train(self, train_samples, train_labels, train_batch_size, iteration_steps):\n",
    "        print('Start Training')\n",
    "        losses = []\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            saver = tf.train.Saver()\n",
    "            \n",
    "            for i in range(iteration_steps):\n",
    "                samples, labels = self.train_minibatch(train_samples, train_labels, train_batch_size)\n",
    "                \n",
    "                feed_dict = {self.input: samples, self.ground_truth: labels, self.is_training: True}\n",
    "                _, loss = sess.run([self.train_op, self.loss], feed_dict=feed_dict)\n",
    "                \n",
    "                if i % 50 == 0:\n",
    "                    print(\"Minibatch loss at step {}: {}\".format(i, loss))\n",
    "                    losses.append([i, loss])\n",
    "                    \n",
    "            saver.save(sess, './model')\n",
    "        return losses\n",
    "                    \n",
    "    def test_minibatch(self, samples, labels, batch_size):\n",
    "        if self.test_pointer + batch_size <= samples.shape[0]:\n",
    "            samples_minibatch = samples[self.test_pointer: self.test_pointer + batch_size]\n",
    "            labels_minibatch = labels[self.test_pointer: self.test_pointer + batch_size]\n",
    "            self.test_pointer += batch_size\n",
    "            end_of_epoch = False\n",
    "        else:\n",
    "            samples_minibatch = samples[self.test_pointer:]\n",
    "            labels_minibatch = labels[self.test_pointer: self.test_pointer + batch_size]\n",
    "            self.test_pointer = 0\n",
    "            end_of_epoch = True\n",
    "        return samples_minibatch, labels_minibatch, end_of_epoch\n",
    "            \n",
    "    def test(self, test_samples, test_labels, test_batch_size):\n",
    "        self.test_pointer = 0\n",
    "        end_of_epoch = False\n",
    "        losses = []\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            saver = tf.train.import_meta_graph(\"./model.meta\")\n",
    "            saver.restore(sess, './model')\n",
    "            while not end_of_epoch:\n",
    "                samples, labels, end_of_epoch = self.test_minibatch(test_samples, test_labels, test_batch_size)\n",
    "                feed_dict = {self.input: samples, self.ground_truth: labels, self.is_training: False}\n",
    "                losses.append(sess.run(self.loss, feed_dict=feed_dict))  \n",
    "        print(\"Average test loss: {}\".format(np.mean(losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WD_FACTOR = 0.0\n",
    "LEARNING_RATE = 0.001\n",
    "model = SVHN_CNN(WD_FACTOR, LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.global_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BATCH_SIZE = 128\n",
    "ITERATIONS = 10000\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "losses = model.train(training_set_gs, training_labels_one_hot, TRAIN_BATCH_SIZE, ITERATIONS)\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Training time: {}s\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    losses = np.array(losses)\n",
    "    np.save('./train_losses.npy', losses)\n",
    "    print(losses.shape)\n",
    "except NameError:\n",
    "    losses = np.load('./train_losses.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "iterations = losses[:, 0]\n",
    "train_loss = losses[:, 1]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(iterations, train_loss, 'b-')\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test network predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_BATCH_SIZE = 128\n",
    "\n",
    "model.test(test_set_gs, test_labels_one_hot, TEST_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = np.random.choice(np.arange(n_test))\n",
    "\n",
    "sample = np.expand_dims(test_set_gs[example], axis=0)\n",
    "label = np.expand_dims(test_labels_one_hot[example], axis=0)\n",
    "\n",
    "digit = np.where(label[0]==1.0)[0][0]\n",
    "\n",
    "feed_dict = {model.input: sample, model.ground_truth: label, model.is_training: False}\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver = tf.train.import_meta_graph(\"./model.meta\")\n",
    "    saver.restore(sess, './model')\n",
    "    prediction = sess.run(model.prediction, feed_dict=feed_dict)[0]\n",
    "\n",
    "image = np.reshape(sample, (32, 32))\n",
    "\n",
    "print(\"Test sample digit: {}\".format(digit))\n",
    "fig, ax = plt.subplots(1, 2, figsize=(17, 5))\n",
    "ax[0].imshow(image, cmap='gray')\n",
    "ax[0].set_title(\"Test example\")\n",
    "\n",
    "classes = np.arange(10)\n",
    "width = 1.0\n",
    "\n",
    "#fig, ax = plt.subplots()\n",
    "ax[1].bar(classes, prediction, width, color='Blue')\n",
    "ax[1].set_ylabel('Probabilities')\n",
    "ax[1].set_title('Network categorical distribution')\n",
    "ax[1].set_xticks(classes)\n",
    "ax[1].set_xticklabels(('0', '1', '2', '3', '4', '5', '6', '7', '8', '9'))\n",
    "ax[1].set_xlabel('Digit class')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"Network prediction probabilities:\")\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
>>>>>>> e01762963b01d9387706731763845a80c6714ac7
